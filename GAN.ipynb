{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torchvision.datasets import MNIST\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = MNIST(root = 'Trainig_data/',\n",
    "             train = True,\n",
    "             download = True, \n",
    "             transform = Compose([ToTensor(), Normalize(mean=(0.5), std = (0.5,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Configuring for better performance\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "img, label = mnist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    out = (x+1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "i = denorm(img)\n",
    "plt.imshow(i[0], cmap = 'gray')\n",
    "print('Label: ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 100\n",
    "data_loader = DataLoader(mnist, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size is some thing that is we are taking batches of 100 each so total baches will be 70000/100 i.e 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_batch, label_batch in data_loader:\n",
    "    print('50th batch')\n",
    "    print(img_batch[50].shape)\n",
    "    plt.imshow(img_batch[50][0], cmap = 'gray')\n",
    "    print( label_batch )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 784\n",
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(img_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, img_size),\n",
    "    nn.Tanh())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(),lr = 0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(),lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(img):\n",
    "    # Created the labels which are later used as input for the BCE loss\n",
    "    real_labels = torch.ones(batch_size, 1).to(device)\n",
    "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "    \n",
    "    #loss for real images\n",
    "    outputs = D(img)\n",
    "    d_loss_real = criterion(outputs, real_labels)\n",
    "    real_score = outputs\n",
    "    \n",
    "    #loss for fake images\n",
    "    z = torch.randn(batch_size, latent_size).to(device)\n",
    "    fake_images = G(z)\n",
    "    outputs = D(fake_images)\n",
    "    d_loss_fake = criterion(outputs, fake_labels)\n",
    "    fake_scores = outputs\n",
    "    \n",
    "    #combine losses\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    #Reset Gradients\n",
    "    reset_grad()\n",
    "    \n",
    "    # Compute gradients\n",
    "    d_loss.backward()\n",
    "    \n",
    "    #Adjust the parameters using backprop\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss, real_score, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = 15\n",
    "for fake_images in range(x):\n",
    "    z = torch.randn(batch_size, latent_size).to(device)\n",
    "    fake_images = G(z)\n",
    "    D(fake_images)\n",
    "    print(denorm(fake_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    # Generate fake images and calculation loss\n",
    "    z = torch.randn(batch_size, latent_size). to(device)\n",
    "    fake_images = G(z)\n",
    "    labels = torch.ones(batch_size, 1).to(device)\n",
    "    g_loss = criterion(D(fake_images), labels)\n",
    "    \n",
    "    \n",
    "    #Backprop and optimizer\n",
    "    reset_grad()\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss, fake_images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "sample_dir = 'samples/'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "for images, _ in data_loader:\n",
    "    images = images.reshape(images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(images), \n",
    "                os.path.join(sample_dir, 'real_images.png'), \n",
    "                nrow = 10)\n",
    "    \n",
    "Image(os.path.join(sample_dir, 'real_images.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vectors = torch.randn(batch_size, latent_size).to(device)\n",
    "\n",
    "def save_fake_images(index):\n",
    "    fake_images = G(sample_vectors)\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
    "    print('Saving', fake_fname)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=10)\n",
    "    \n",
    "# Before training\n",
    "save_fake_images(0)\n",
    "Image(os.path.join(sample_dir, 'fake_images-0000.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_epochs = 100\n",
    "total_step = len(data_loader)\n",
    "d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        # Load a batch & transform to vectors\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        \n",
    "        # Train the discriminator and generator\n",
    "        d_loss, real_score, fake_score = train_discriminator(images)\n",
    "        g_loss, fake_images = train_generator()\n",
    "        \n",
    "        # Inspect the losses\n",
    "        if (i+1) % 200 == 0:\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "            real_scores.append(real_score.mean().item())\n",
    "            fake_scores.append(fake_score.mean().item())\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "        \n",
    "    # Sample and save images\n",
    "    save_fake_images(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "video_avi = 'GAN_Output.avi'\n",
    "\n",
    "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\n",
    "files.sort()\n",
    "\n",
    "out = cv2.VideoWriter(video_avi,cv2.VideoWriter_fourcc(*'MP4V'), 8, (302,302))\n",
    "[out.write(cv2.imread(fname)) for fname in files]\n",
    "out.release()\n",
    "FileLink('GAN_Output.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses, '-')\n",
    "plt.plot(g_losses, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_scores, '-')\n",
    "plt.plot(fake_scores, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "plt.legend(['Real Score', 'Fake score'])\n",
    "plt.title('Scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
